# 图神经网络

## 零基础多图详解图神经网络（GNN/GCN）【论文精读】

> 李沐

A Gentle Introduction of Graph Neural Network

from Google Research, distill publications

Graph are all around us. We are starting to see practical applications recently.

This article explores and explains modern neural network.

- what kind of data is most natually phrased as a graph
- what makes graph different from other types of data
- to build a GNN, walking through each parts
- we provide a GNN playground

A graph represents the relations (edges) between collection of entities (nodes).

- V: Vertex (or node) attributes
- E: Edge (or link) attributes and directions
- U: Global (or master node) attributes

Graph: Undirected edge, or directed edge

### Graphs and where to find it

- Images as graphs
  - typically, $244 \times 244 \times 3$ floats
  - image pixels -> adjacent matrix -> graph
- Text as graphs
- Graph-valued data in the wild
  - Molecules as graphs
  - Social networks as graphs
  - Citation networks as graphs
  - Other examples: Machine learning models, programming code, and math equations

### What types of problems have graph structured data?

- Graph-level task
- Node-level task
- Edge-level task
  - segmentaion -> relation between people
  - input: fully connected graph, unlabeled edges
  - output: labels for edges

### The challenges of using graphs in machine learning

Groups have up to four types of info that we will potentially want to use to make predictions:

- nodes
- edges
- global-context
- connectivity

How to represent connectivity? -> adjencency matrix. But there might be some problems:

- size of the matrix -> sparse matrix
- adjencency matrix是行列对称的，放到神经网络之后，可能导致行列不对称

换一种存储方法：adjencency list

- Nodes: [0, 0, 1, 0, 0, 0, 1, 1]
- Edges: [1, 1, 1, 2, 2, 1, 2]
- Adjacency list: [[1, 0], [2, 0], [4, 3], [6, 2], [7, 3], [7, 4], [7, 5]]
- Global: 0

这样的表示既存储高效，也是对顺序无关的。

### Graph Neural Networks

A GNN is an optimizable tranformation on all attributes of the graph (nodes, graph, global-context) that preserves graph symmetries (permutation invariances).

We are gonna build GNNs using the ...

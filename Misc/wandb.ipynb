{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb\n",
    "\n",
    "## wandbÊàëÊúÄÁà±ÁöÑÁÇº‰∏π‰º¥‰æ£Êìç‰ΩúÊåáÂçó\n",
    "\n",
    "> [wandbÊàëÊúÄÁà±ÁöÑÁÇº‰∏π‰º¥‰æ£Êìç‰ΩúÊåáÂçó](https://www.bilibili.com/video/BV17A41167WX/?share_source=copy_web&vd_source=724ca2fcd803a56b1646d6d28e65b820)\n",
    "\n",
    "### Intro\n",
    "\n",
    "wandbÂÖ®Áß∞weights&biasÔºåÂ§ßÂè∑tensorboardÔºå‰ºòÂäøÔºö\n",
    "\n",
    "- logÂ≠òÂÇ®Âú®‰∫ëÁ´ØÔºå‰æøÂàÜ‰∫´‰∏ç‰∏¢Â§±„ÄÇ\n",
    "- ÂèØ‰ª•Â≠ò‰ª£Á†ÅÔºåÊï∞ÊçÆÈõÜÂíåÊ®°ÂûãÁöÑÁâàÊú¨ÔºåÈöèÊó∂Â§çÁé∞  (`wandb.Artifact`)\n",
    "- ‰∫§‰∫íÂºèË°®Ê†ºÔºåËøõË°åcaseÂàÜÊûê (`wandb.Table`)\n",
    "- ÂèØ‰ª•Ëá™Âä®ÂåñÊ®°ÂûãË∞ÉÂèÇ (`wandb.sweep`)\n",
    "  - ÊúÄÈáçË¶ÅÁöÑ‰∏ÄÁÇπ\n",
    "  - È´òÊïà‰ºòÈõÖ\n",
    "\n",
    "ÂÆòÊñπ‰ªãÁªçÔºö\n",
    "\n",
    "- Experiments\n",
    "- Artifacts\n",
    "- Tables\n",
    "- Sweeps\n",
    "- Reports\n",
    "\n",
    "ÂØπÂ∏∏Áî®ÁöÑframeworkÈÉΩÂÅö‰∫ÜÈõÜÊàê„ÄÇ\n",
    "\n",
    "ÊÄª‰ΩìËÄåË®ÄÔºåÂõõ‰∏™Ê†∏ÂøÉÂäüËÉΩÔºö\n",
    "\n",
    "- ÂÆûÈ™åË∑üË∏™\n",
    "- ÁâàÊú¨ÁÆ°ÁêÜ\n",
    "- caseÂàÜÊûê\n",
    "- Ë∂ÖÂèÇË∞É‰ºò\n",
    "\n",
    "### Experience\n",
    "\n",
    "##### 0. Ê≥®ÂÜåwandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (SSLError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"xxxxxxxxxxxxxxxxx\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"wandb\"\n",
    "os.environ['WANDB_DISABLE_CODE'] = 'true'\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.ÂÆûÈ™åË∑üË∏™\n",
    "\n",
    "wandbÊèê‰æõ‰∫ÜÁ±ª‰ººTensorBoardÁöÑÂÆûÈ™åË∑üË∏™ËÉΩÂäõÔºå‰∏ªË¶ÅÂåÖÊã¨Ôºö\n",
    "\n",
    "- Ê®°ÂûãÈÖçÁΩÆË∂ÖÂèÇÊï∞ÁöÑËÆ∞ÂΩï\n",
    "- Ê®°ÂûãËÆ≠ÁªÉËøáÁ®ã‰∏≠lossÔºåmetricÁ≠âÂêÑÁßçÊåáÊ†áÁöÑËÆ∞ÂΩïÂíåÂèØËßÜÂåñ\n",
    "- ÂõæÂÉèÁöÑÂèØËßÜÂåñÔºàwandb.ImageÔºâ\n",
    "- ÂÖ∂‰ªñÂêÑÁßçMediaÔºàwandb.Video, wandb.Audio, wandb.Html, 3DÁÇπ‰∫ëÁ≠âÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, PIL\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import datetime\n",
    "from argparse import Namespace\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = Namespace(\n",
    "    project_name = 'wandb_demo',\n",
    "\n",
    "    batch_size = 512,\n",
    "    hidden_layer_width = 64,\n",
    "    dropout_p = 0.1,\n",
    "\n",
    "    lr = 1e-4,\n",
    "    optim_type = 'Adam',\n",
    "\n",
    "    epochs = 15,\n",
    "    ckpt_path = 'checkpoint.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(config):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_train = torchvision.datasets.MNIST(root=\"./mnist/\",train=True,download=True,transform=transform)\n",
    "    ds_val = torchvision.datasets.MNIST(root=\"./mnist/\",train=False,download=True,transform=transform)\n",
    "\n",
    "    ds_train_sub = torch.utils.data.Subset(ds_train, indices=range(0, len(ds_train), 5))\n",
    "    dl_train =  torch.utils.data.DataLoader(ds_train_sub, batch_size=config.batch_size, shuffle=True,\n",
    "                                            num_workers=2,drop_last=True)\n",
    "    dl_val =  torch.utils.data.DataLoader(ds_val, batch_size=config.batch_size, shuffle=False, \n",
    "                                          num_workers=2,drop_last=True)\n",
    "    return dl_train,dl_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_net(config):\n",
    "    net = nn.Sequential()\n",
    "    net.add_module(\"conv1\",nn.Conv2d(in_channels=1,out_channels=config.hidden_layer_width,kernel_size = 3))\n",
    "    net.add_module(\"pool1\",nn.MaxPool2d(kernel_size = 2,stride = 2)) \n",
    "    net.add_module(\"conv2\",nn.Conv2d(in_channels=config.hidden_layer_width,\n",
    "                                     out_channels=config.hidden_layer_width,kernel_size = 5))\n",
    "    net.add_module(\"pool2\",nn.MaxPool2d(kernel_size = 2,stride = 2))\n",
    "    net.add_module(\"dropout\",nn.Dropout2d(p = config.dropout_p))\n",
    "    net.add_module(\"adaptive_pool\",nn.AdaptiveMaxPool2d((1,1)))\n",
    "    net.add_module(\"flatten\",nn.Flatten())\n",
    "    net.add_module(\"linear1\",nn.Linear(config.hidden_layer_width,config.hidden_layer_width))\n",
    "    net.add_module(\"relu\",nn.ReLU())\n",
    "    net.add_module(\"linear2\",nn.Linear(config.hidden_layer_width,10))\n",
    "    net.to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dl_train,optimizer):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(dl_train):\n",
    "        features,labels = batch\n",
    "        features,labels = features.to(device),labels.to(device)\n",
    "\n",
    "        preds = model(features)\n",
    "        loss = nn.CrossEntropyLoss()(preds,labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model,dl_val):\n",
    "    model.eval()\n",
    "    accurate = 0\n",
    "    num_elems = 0\n",
    "    for batch in dl_val:\n",
    "        features,labels = batch\n",
    "        features,labels = features.to(device),labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(features)\n",
    "        predictions = preds.argmax(dim=-1)\n",
    "        accurate_preds =  (predictions==labels)\n",
    "        num_elems += accurate_preds.shape[0]\n",
    "        accurate += accurate_preds.long().sum()\n",
    "\n",
    "    val_acc = accurate.item() / num_elems\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config = config):\n",
    "    dl_train, dl_val = create_dataloaders(config)\n",
    "    model = create_net(config); \n",
    "    optimizer = torch.optim.__dict__[config.optim_type](params=model.parameters(), lr=config.lr)\n",
    "    #======================================================================\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    wandb.init(project=config.project_name, config = config.__dict__, name = nowtime, save_code=True, mode=\"offline\")\n",
    "    model.run_id = wandb.run.id\n",
    "    #======================================================================\n",
    "    model.best_metric = -1.0\n",
    "    for epoch in range(1,config.epochs+1):\n",
    "        model = train_epoch(model,dl_train,optimizer)\n",
    "        val_acc = eval_epoch(model,dl_val)\n",
    "        if val_acc>model.best_metric:\n",
    "            model.best_metric = val_acc\n",
    "            torch.save(model.state_dict(),config.ckpt_path)   \n",
    "        nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"epoch„Äê{epoch}„Äë@{nowtime} --> val_acc= {100 * val_acc:.2f}%\")\n",
    "        #======================================================================\n",
    "        wandb.log({'epoch':epoch, 'val_acc': val_acc, 'best_val_acc':model.best_metric})\n",
    "        #======================================================================        \n",
    "    #======================================================================\n",
    "    wandb.finish()\n",
    "    #======================================================================\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch„Äê1„Äë@2024-07-12 15:30:46 --> val_acc= 29.52%\n",
      "epoch„Äê2„Äë@2024-07-12 15:30:49 --> val_acc= 29.91%\n",
      "epoch„Äê3„Äë@2024-07-12 15:30:52 --> val_acc= 37.94%\n",
      "epoch„Äê4„Äë@2024-07-12 15:30:55 --> val_acc= 50.54%\n",
      "epoch„Äê5„Äë@2024-07-12 15:30:58 --> val_acc= 59.88%\n",
      "epoch„Äê6„Äë@2024-07-12 15:31:01 --> val_acc= 68.98%\n",
      "epoch„Äê7„Äë@2024-07-12 15:31:03 --> val_acc= 76.30%\n",
      "epoch„Äê8„Äë@2024-07-12 15:31:06 --> val_acc= 79.64%\n",
      "epoch„Äê9„Äë@2024-07-12 15:31:09 --> val_acc= 82.93%\n",
      "epoch„Äê10„Äë@2024-07-12 15:31:12 --> val_acc= 85.29%\n",
      "epoch„Äê11„Äë@2024-07-12 15:31:15 --> val_acc= 86.87%\n",
      "epoch„Äê12„Äë@2024-07-12 15:31:18 --> val_acc= 88.03%\n",
      "epoch„Äê13„Äë@2024-07-12 15:31:21 --> val_acc= 88.80%\n",
      "epoch„Äê14„Äë@2024-07-12 15:31:24 --> val_acc= 89.71%\n",
      "epoch„Äê15„Äë@2024-07-12 15:31:27 --> val_acc= 90.42%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>val_acc</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.90419</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>val_acc</td><td>0.90419</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/ma-user/work/kb24fall/Miscellaneous/wandb/offline-run-20240712_153003-s14drwl9<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20240712_153003-s14drwl9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(config) ##3,2,1 ÁÇπÁÅ´üî•üî•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

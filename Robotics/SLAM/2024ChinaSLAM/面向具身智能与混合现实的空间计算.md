# 面向具身智能与混合现实的空间计算

> 圆桌论坛

## TODO

- [ ] active learning
- [ ] UMI from Stanford

## 具身智能与混合现实对空间计算带来了哪些新的挑战？

- 过去可能觉得pose可能是个好的representation，但现阶段pose不一定够，可能还有affordance、mobility等等。从具身智能的角度看三维视觉看，还有很多挑战。
- 对于混合现实来讲，对于功耗的要求很高，可能是依托于穿戴式的眼镜，和机器人硬件的诉求会不一样，对research来讲是个很好的机会。
- 空间计算的输入有所丰富，比如视觉的空间计算的输入只有图片，如今具身智能的输入是多模态的。从输出来讲，过去是pose，在具身来讲，输出可能希望是一个action。MLLMs可以引入外部常识信息丰富了空间计算。
- 多机协同问题。

## 面向具身智能与混合现实的空间计算中的数据瓶颈问题：什么是高质量的具身智能数据？如何高效获取与扩充？如何解决具身智能模型面临的sim2real问题？

- 解决两个问题：数据能用，然后才是数据好用。需要找到一种可扩展的数据获取方式，低成本的数据采集方式，有没有一种可能由真实数据获取3d位姿用于合成数据，这样更容易scale up
- 有3d视觉背景的人去搞生成数据有很大的背景，清理数据，高质量小数据，生成数据上需要有一些diversity（仅基于人类的规则是很差的），对于真实数据的规则是很难描述，所以我们才需要真实的数据，通过隐式的方式去学习。
- 好的具身智能数据应该能干活解决问题、被学习、能拓展迁移、体量大应该易于获取，我们应该更多地思考应该采集什么样的数据，active learaning，泛化性，比如UMI的各种grippers都能用，从泛化性来讲仿真可以做更多的random domain，保证仿真又快又好。

## 面向具身智能与混合现实中的空间计算，在制造业等行业中面临的重要挑战是什么？大模型如何发挥作用？

- 工业界的成本很高，定制性可以做的很好但是不能泛化，大模型的优势在此，现在可以去做一些open-domain的工作，一个通用的框架可以解决各种问题。具身智能和混合现实还是不一样，混合现实的爆发还是需要toC的，这对于成本与效率带来更多的挑战，以及内容生产的效率等等，如果挣不到钱的话为什么这些人不去做游戏做电影？AIGC的到来让普通人也有机会接触到混合现实等等，这带来一个toC的希望。
- 面向制造应用，学术界和落地会有gap，泛化性和可扩展性的获取是比较难的，以及不同场景的适配。

## SLAM与具身智能机器人的结合和未来前景

## SLAM技术是否已经成熟，还有哪些需要研究的问题？SLAM是否回被端到端方案替代？

- mapping需要更加结构化，可以更好的planning，可以selective focus，对dynamic object更加robust，对于hardware的强适应性。
